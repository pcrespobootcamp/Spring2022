{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5c4786-8953-42b9-a500-256a0ba3b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.formula.api as smf\n",
    "from numpy import random\n",
    "\n",
    "from plotnine import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7977c3b-6d7a-44c3-8579-51e5bd8be465",
   "metadata": {},
   "source": [
    "# Differences in differences\n",
    "\n",
    "We have thought of events as treatments, and we have usually applied it to samples all at the same time. But what happens if we consider the specific effect of a policy that is established at one point in time and then it remains as such.\n",
    "\n",
    "Consider for example a change in tax law that increases rates for the wealthiest people in a country. We would be very interested to see if that actually increases the tax revenue of the country significantly. Furthermore, we would like this to see if this effect can be persistent. \n",
    "\n",
    "But, in this case we only have one unit ( a single country) treated. Perhaps, we could think of looking at how the trend of tax revenue looks like before and after the policy has happened and use that difference as our treatment effect. However, we find that this might not be the effect we are looking for. Why?\n",
    "\n",
    "In general we would be looking to see if the trends change, but trends can change for more reasons than simply the treatment. In our case we can have that for example an industry boom in a very profitable technology field creates lots of new wealthy individuals, thus affecting the trend. This would make it difficult to examine the effect of the treatment.\n",
    "\n",
    "What can we do?\n",
    "\n",
    "Well, maybe we can grab another country that is very similar to the one that gets the policy, but that it did not get it. The problem is that unlike experiments, we cannot generate comparability by having a large enough number of units that could give us the way to make the comparison in distributions. But, maybe if they are comparable enough, we can do something else.\n",
    "\n",
    "One of the things we have become good at doing is generating predictions. We can actually generate a \"what if\" had the treatment had never happened to the treated unit. We call this a counterfactual. If we find a control unit that has a parallel trend to the treated unit, we can use the period prior to the treatment to extrapolate the counterfactual in the post treatment period and use the difference from the actual observations on the treated unit as our treatment effect.\n",
    "\n",
    "\n",
    "Let's show a plot to make it less confusing:\n",
    "\n",
    "![Parallel](https://miro.medium.com/max/606/1*5mHmHpDaqYoWn5BqQ0a77w.png)\n",
    "\n",
    "\n",
    "So using the fits in the pretreatment stage of paralell units where one has not been treated, we can use the fit and further time observarions as our counterfactual. Then the difference with the post treatment outcomes will give us our effect. \n",
    "\n",
    "Using our potential outcomes notation to define our treatment effect:\n",
    "\n",
    "\n",
    "* $Y^1_{Pre}$ is the treated unit before the treatment\n",
    "\n",
    "* $Y^0_{Pre}$ is the control unit before the treatment\n",
    "\n",
    "* $Y^1_{Post}$ is the treated unit after the treatment\n",
    "\n",
    "* $Y^0_{Post}$ is the control unit after the treatment\n",
    "\n",
    "\n",
    "So we get that:\n",
    "\n",
    "$$\\hat{\\delta}=mean(Y^1_{Post}-Y^0_{Post})-mean(Y^1_{Pre}-Y^0_{Pre})$$\n",
    "\n",
    "Hence the name! \n",
    "Recall that:\n",
    "\n",
    "$$T=\\begin{cases}\n",
    "        1, \\mbox{if Treated}\\\\ \n",
    "        0, \\mbox{Otherwise} \\\\\n",
    "        \\end{cases}$$\n",
    "        \n",
    "        \n",
    "And now let's define:\n",
    "\n",
    "$$A=\\begin{cases}\n",
    "        1, \\mbox{if in post-treatment time}\\\\ \n",
    "        0, \\mbox{if in pre-treatment time} \\\\\n",
    "        \\end{cases}$$\n",
    "\n",
    "\n",
    "So now we can estimate $\\delta$ by using the following regression for individuals $i$ at time $t$:\n",
    "\n",
    "$$Y_{it}=\\alpha+\\gamma T+\\lambda A+\\delta (TA)+\\varepsilon_{it}$$\n",
    "\n",
    "Wait, how?\n",
    "\n",
    "This can be seen easily when we note that while setting the appropriate values to 1 or zero we get:\n",
    "\n",
    "* $Y^0_{Pre}= \\alpha$\n",
    "\n",
    "* $Y^0_{Post}= \\alpha+ \\lambda$\n",
    "\n",
    "* $Y^1_{Pre}= \\alpha+ \\gamma$\n",
    "\n",
    "* $Y^1_{Post}= \\alpha+ \\gamma+\\lambda+\\delta$\n",
    "\n",
    "\n",
    "Now note:\n",
    "\n",
    "$$Y^1_{Pre}-Y^0_{Pre}=\\alpha+\\gamma-\\alpha= \\gamma$$\n",
    "\n",
    "And:\n",
    "\n",
    "$$Y^1_{Post}-Y^0_{Post}=\\alpha+ \\gamma+\\lambda+\\delta-(\\alpha+\\lambda)= \\gamma+\\delta$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$(Y^1_{Post}-Y^0_{Post})-(Y^1_{Pre}-Y^0_{Pre})=\\gamma+\\delta-\\gamma=\\delta$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f6018-3a27-46f8-8628-15f1f26c31b6",
   "metadata": {},
   "source": [
    "## Minimum wage, the Nobel Prize and estimation\n",
    "\n",
    "\n",
    "One of the papers that got David Card his part of the Nobel in Economics in 2021 tried to determine the effects of minimum wage on employment. For this him and Alan Krueger used data from fast food employees in New Jersey and Pennsylvania. Why? Let's see the story:\n",
    "\n",
    "* In November 1992 the minumum wage in NJ went from 4.25 dollars an hour to 5.05\n",
    "\n",
    "* Pennsylvania is neighboring state similar in many aspects but there was no change to happen in minimum wage\n",
    "\n",
    "* Using multiple restaurants they decided to take a survey before the change in policy in february, and repeat it in November.\n",
    "\n",
    "\n",
    "The plot they got would look something like this in the best of cases (Taken from Causal Inference: The Mixtape by Scott Cunningham):\n",
    "\n",
    "![Fig1](https://mixtape.scunning.com/causal_inference_mixtape_files/figure-html/dd-diagram-1.png)\n",
    "\n",
    "\n",
    "But you might note there is a problem... the trends are not parallel...\n",
    "\n",
    "Why is that a problem... well. Let's observe another plot from Scott's book to see what is going on:\n",
    "\n",
    "![Fig2](https://mixtape.scunning.com/causal_inference_mixtape_files/figure-html/dd-diagram2-1.png)\n",
    "\n",
    "$\\delta_{ATT}$ is the true parameter we want to estimate. However, the linear regression is giving us the one with the light gray line. Hence why we would like to have the parallel trends stand.\n",
    "\n",
    "An important lesson for us:\n",
    "\n",
    "* We need more than one period pre and post control\n",
    "\n",
    "* We need to check the parallel trend assumption\n",
    "\n",
    "For now we can use the data for the paper and replicate the regression anyway. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8953b4a5-d15d-4b54-8a9b-41f43f53acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "\n",
    "df = pd.read_csv('njmin3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9ffcf6-8506-4850-9116-f5d5bed23bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_OWNED</th>\n",
       "      <th>SOUTHJ</th>\n",
       "      <th>CENTRALJ</th>\n",
       "      <th>PA1</th>\n",
       "      <th>PA2</th>\n",
       "      <th>DEMP</th>\n",
       "      <th>nj</th>\n",
       "      <th>bk</th>\n",
       "      <th>kfc</th>\n",
       "      <th>roys</th>\n",
       "      <th>wendys</th>\n",
       "      <th>d</th>\n",
       "      <th>d_nj</th>\n",
       "      <th>fte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO_OWNED  SOUTHJ  CENTRALJ  PA1  PA2   DEMP  nj  bk  kfc  roys  wendys  d  \\\n",
       "0         0       0         1    0    0  12.00   1   1    0     0       0  0   \n",
       "1         0       0         1    0    0   6.50   1   1    0     0       0  0   \n",
       "2         0       0         1    0    0  -1.00   1   0    0     1       0  0   \n",
       "3         1       0         0    0    0   2.25   1   0    0     1       0  0   \n",
       "4         0       0         0    0    0  13.00   1   1    0     0       0  0   \n",
       "\n",
       "   d_nj    fte  \n",
       "0     0  15.00  \n",
       "1     0  15.00  \n",
       "2     0  24.00  \n",
       "3     0  19.25  \n",
       "4     0  21.50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5378c6-6ebc-40b0-aa5c-8730e5c1ff85",
   "metadata": {},
   "source": [
    "Let's examine what we have for variables:\n",
    "\n",
    "\n",
    "* nj=1 if New Jersey\n",
    "* d=1 if after minimum wage increase\n",
    "* d_nj=1 nj and d interaction\n",
    "* fte  full time equivalent employees\n",
    "* bk=1 if Burger King\n",
    "* kfc=1 if KFC\n",
    "* roys=1 if Roy Rodgers\n",
    "* wendys=1 if Wendy's\n",
    "* co_owned=1 if company owned\n",
    "* centralj=1 if Central NJ\n",
    "* southj=1 if Southern NJ\n",
    "* pa1=1 if in PA, northeast suburbs of Philadelphia\n",
    "* pa2=1 if PA, Easton, etc\n",
    "\n",
    "Let's check with our regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4285c6d9-7a07-4071-96a9-7bbcd28596d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>fte</td>       <th>  R-squared:         </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Nov 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.118</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:11:07</td>     <th>  Log-Likelihood:    </th> <td> -2904.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   794</td>      <th>  AIC:               </th> <td>   5816.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   790</td>      <th>  BIC:               </th> <td>   5835.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   23.3312</td> <td>    1.072</td> <td>   21.767</td> <td> 0.000</td> <td>   21.227</td> <td>   25.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nj</th>        <td>   -2.8918</td> <td>    1.194</td> <td>   -2.423</td> <td> 0.016</td> <td>   -5.235</td> <td>   -0.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d</th>         <td>   -2.1656</td> <td>    1.516</td> <td>   -1.429</td> <td> 0.154</td> <td>   -5.141</td> <td>    0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d_nj</th>      <td>    2.7536</td> <td>    1.688</td> <td>    1.631</td> <td> 0.103</td> <td>   -0.561</td> <td>    6.068</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>218.742</td> <th>  Durbin-Watson:     </th> <td>   1.842</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 804.488</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.268</td>  <th>  Prob(JB):          </th> <td>2.03e-175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.229</td>  <th>  Cond. No.          </th> <td>    11.3</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    fte   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.004\n",
       "Method:                 Least Squares   F-statistic:                     1.964\n",
       "Date:                Thu, 18 Nov 2021   Prob (F-statistic):              0.118\n",
       "Time:                        16:11:07   Log-Likelihood:                -2904.2\n",
       "No. Observations:                 794   AIC:                             5816.\n",
       "Df Residuals:                     790   BIC:                             5835.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     23.3312      1.072     21.767      0.000      21.227      25.435\n",
       "nj            -2.8918      1.194     -2.423      0.016      -5.235      -0.549\n",
       "d             -2.1656      1.516     -1.429      0.154      -5.141       0.810\n",
       "d_nj           2.7536      1.688      1.631      0.103      -0.561       6.068\n",
       "==============================================================================\n",
       "Omnibus:                      218.742   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              804.488\n",
       "Skew:                           1.268   Prob(JB):                    2.03e-175\n",
       "Kurtosis:                       7.229   Cond. No.                         11.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1 = smf.ols('fte ~ nj+d+d_nj', df).fit()\n",
    "\n",
    "reg1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df61f5-73a4-4b9f-8ad4-430c6e585420",
   "metadata": {},
   "source": [
    "This tells us that the effect on employment is 2.7536 but that it is insignificant.\n",
    "\n",
    "If assumptions are well met we would be able to say that there is no significant effect of the minimum wage increase on employment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e9e25-0a91-46e8-9e41-40c6b6c57536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
